<!DOCTYPE html><html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type" /><meta content="width=device-width, initial-scale=1" name="viewport" /><!--replace-start-0--><!--replace-start-5--><!--replace-start-8--><title>Bayes&#39; theorem - My Zettelkasten</title><!--replace-end-8--><!--replace-end-5--><!--replace-end-0--><link href="https://cdn.jsdelivr.net/npm/fomantic-ui@2.8.7/dist/semantic.min.css" rel="stylesheet" /><link href="https://fonts.googleapis.com/css?family=Merriweather|Libre+Franklin|Roboto+Mono&amp;display=swap" rel="stylesheet" /><!--replace-start-1--><!--replace-start-4--><!--replace-start-7--><link href="https://raw.githubusercontent.com/srid/neuron/master/assets/neuron.svg" rel="icon" /><meta content="Deduction works from the general to the particular. Event A is observed, and event B is unobserved. If event B is part of A, then to assign characteristics of A to B is relatively simple." name="description" /><meta content="Bayes&#39; theorem" property="og:title" /><meta content="My Zettelkasten" property="og:site_name" /><meta content="article" property="og:type" /><script type="application/ld+json">[]</script><style type="text/css">body{background-color:#eeeeee !important;font-family:"Libre Franklin", serif !important}body .ui.container{font-family:"Libre Franklin", serif !important}body h1, h2, h3, h4, h5, h6, .ui.header, .headerFont{font-family:"Merriweather", sans-serif !important}body code, pre, tt, .monoFont{font-family:"Roboto Mono","SFMono-Regular","Menlo","Monaco","Consolas","Liberation Mono","Courier New", monospace !important}body div.z-index p.info{color:#808080}body div.z-index ul{list-style-type:square;padding-left:1.5em}body div.z-index .uplinks{margin-left:0.29999em}body .zettel-content h1#title-h1{background-color:rgba(33,133,208,0.1)}body nav.bottomPane{background-color:rgba(33,133,208,2.0e-2)}body div#footnotes{border-top-color:#2185d0}body p{line-height:150%}body img{max-width:100%}body .deemphasized{font-size:0.94999em}body .deemphasized:hover{opacity:1}body .deemphasized:not(:hover){opacity:0.69999}body .deemphasized:not(:hover) a{color:#808080 !important}body div.container.universe{padding-top:1em}body div.zettel-view ul{padding-left:1.5em;list-style-type:square}body div.zettel-view .pandoc .highlight{background-color:#ffff00}body div.zettel-view .pandoc .ui.disabled.fitted.checkbox{margin-right:0.29999em;vertical-align:middle}body div.zettel-view .zettel-content .metadata{margin-top:1em}body div.zettel-view .zettel-content .metadata div.date{text-align:center;color:#808080}body div.zettel-view .zettel-content h1{padding-top:0.2em;padding-bottom:0.2em;text-align:center}body div.zettel-view .zettel-content h2{border-bottom:solid 1px #4682b4;margin-bottom:0.5em}body div.zettel-view .zettel-content h3{margin:0px 0px 0.4em 0px}body div.zettel-view .zettel-content h4{opacity:0.8}body div.zettel-view .zettel-content div#footnotes{margin-top:4em;border-top-style:groove;border-top-width:2px;font-size:0.9em}body div.zettel-view .zettel-content div#footnotes ol > li > p:only-of-type{display:inline;margin-right:0.5em}body div.zettel-view .zettel-content aside.footnote-inline{width:30%;padding-left:15px;margin-left:15px;float:right;background-color:#d3d3d3}body div.zettel-view .zettel-content .overflows{overflow:auto}body div.zettel-view .zettel-content code{margin:auto auto auto auto;font-size:100%}body div.zettel-view .zettel-content p code, li code, ol code{padding:0.2em 0.2em 0.2em 0.2em;background-color:#f5f2f0}body div.zettel-view .zettel-content pre{overflow:auto}body div.zettel-view .zettel-content dl dt{font-weight:bold}body div.zettel-view .zettel-content blockquote{background-color:#f9f9f9;border-left:solid 10px #cccccc;margin:1.5em 0px 1.5em 0px;padding:0.5em 10px 0.5em 10px}body div.zettel-view .zettel-content.raw{background-color:#dddddd}body .ui.label.zettel-tag{color:#000000}body .ui.label.zettel-tag a{color:#000000}body nav.bottomPane ul.backlinks > li{padding-bottom:0.4em;list-style-type:disc}body nav.bottomPane ul.context-list > li{list-style-type:lower-roman}body .footer-version img{-webkit-filter:grayscale(100%);-moz-filter:grayscale(100%);-ms-filter:grayscale(100%);-o-filter:grayscale(100%);filter:grayscale(100%)}body .footer-version img:hover{-webkit-filter:grayscale(0%);-moz-filter:grayscale(0%);-ms-filter:grayscale(0%);-o-filter:grayscale(0%);filter:grayscale(0%)}body .footer-version, .footer-version a, .footer-version a:visited{color:#808080}body .footer-version a{font-weight:bold}body .footer-version{margin-top:1em !important;font-size:0.69999em}@media only screen and (max-width: 768px){body div#zettel-container{margin-left:0.4em !important;margin-right:0.4em !important}}body span.zettel-link-container span.zettel-link a{color:#2185d0;font-weight:bold;text-decoration:none}body span.zettel-link-container span.zettel-link a:hover{background-color:rgba(33,133,208,0.1)}body span.zettel-link-container span.extra{color:auto}body span.zettel-link-container.errors{border:solid 1px #ff0000}body span.zettel-link-container.errors span.zettel-link a:hover{text-decoration:none !important;cursor:not-allowed}body [data-tooltip]:after{font-size:0.69999em}body div.tag-tree div.node{font-weight:bold}body div.tag-tree div.node a.inactive{color:#555555}body .tree.flipped{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);-o-transform:rotate(180deg);transform:rotate(180deg)}body .tree{overflow:auto}body .tree ul.root{padding-top:0px;margin-top:0px}body .tree ul{position:relative;padding:1em 0px 0px 0px;white-space:nowrap;margin:0px auto 0px auto;text-align:center}body .tree ul::after{content:"";display:table;clear:both}body .tree ul:last-child{padding-bottom:0.1em}body .tree li{display:inline-block;vertical-align:top;text-align:center;list-style-type:none;position:relative;padding:1em 0.5em 0em 0.5em}body .tree li::before{content:"";position:absolute;top:0px;right:50%;border-top:solid 2px #cccccc;width:50%;height:1.19999em}body .tree li::after{content:"";position:absolute;top:0px;right:50%;border-top:solid 2px #cccccc;width:50%;height:1.19999em}body .tree li::after{right:auto;left:50%;border-left:solid 2px #cccccc}body .tree li:only-child{padding-top:0em}body .tree li:only-child::after{display:none}body .tree li:only-child::before{display:none}body .tree li:first-child::before{border-style:none;border-width:0px}body .tree li:first-child::after{border-radius:5px 0px 0px 0px}body .tree li:last-child::after{border-style:none;border-width:0px}body .tree li:last-child::before{border-right:solid 2px #cccccc;border-radius:0px 5px 0px 0px}body .tree ul ul::before{content:"";position:absolute;top:0px;left:50%;border-left:solid 2px #cccccc;width:0px;height:1.19999em}body .tree li div.forest-link{border:solid 2px #cccccc;padding:0.2em 0.29999em 0.2em 0.29999em;text-decoration:none;display:inline-block;border-radius:5px 5px 5px 5px;color:#333333;position:relative;top:2px}body .tree.flipped li div.forest-link{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);-o-transform:rotate(180deg);transform:rotate(180deg)}</style><!-- MathJax -->
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- Prism.js -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css" rel="stylesheet" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-core.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/plugins/autoloader/prism-autoloader.min.js"></script>
<!-- Mermaid.js -->
<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>
    window.addEventListener("load", mermaid.initialize(
        {
            startOnLoad: true
        }
    ))
</script>
<!-- Custom CSS -->
<link href="./static/style.css" rel="stylesheet" />
<!--replace-end-7--><!--replace-end-4--><!--replace-end-1--></head><body><div class="ui fluid container universe"><!--replace-start-2--><!--replace-start-3--><!--replace-start-6--><nav class="flipped tree deemphasized" id="zettel-uptree" style="transform-origin: 50%"><ul class="root"><li><ul><li><div class="forest-link"><span class="zettel-link-container"><span class="zettel-link" title="2021-04-06T18:54"><a href="9f8d74d6.html">Methods for statistical analysis 1 (CAMAEI)</a></span></span></div><ul><li><div class="forest-link"><span class="zettel-link-container"><span class="zettel-link" title="2021-04-05T13:33"><a href="4d2b51b4.html">First semester</a></span></span></div><ul><li><div class="forest-link"><span class="zettel-link-container"><span class="zettel-link" title="2021-04-04T23:09"><a href=".">Index</a></span></span></div></li></ul></li></ul></li></ul></li></ul></nav><div class="ui text container" id="zettel-container" style="position: relative"><div class="zettel-view"><article class="ui raised attached segment zettel-content"><div class="pandoc"><h1 id="title-h1">Bayes&#39; theorem</h1><h2 id="deduction-induction-and-statistical-inference">Deduction, induction and statistical inference</h2><p><strong>Deduction</strong> works from the general to the particular. Event A is observed, and event B is unobserved. If event B is part of A, then to assign characteristics of A to B is relatively simple.</p><p>For example: «offsprign fo mammals are extremely dependent of their parents». We can distinguish all the mammals as A, and all the humans as B, where the humans correspond to a subset of the mammals. Then the conclusion: «offspring of humans are extremely dependent of their parents» is direct.</p><p><strong>Induction</strong> is a much more difficult task, for it works from the particular to the general, with the possibility of error. The <strong>statiscial inference</strong> is an inductive process in which we make statements about a parameter on the basis of an observed statistic (e.g. the mean of a sample).</p><h2 id="types-of-probabilities">Types of probabilities</h2><h3 id="joint-probability">Joint probability</h3><p><strong>Joint probability</strong> of A and B is the probability that both events occur simultaneously. A is an observed event, and B is not, and their joint probability is their intersection.</p><p><span class="math display">$$
P(A \cap B)
$$</span></p><p>Two events are <strong>independent</strong> if their joint probability if the joint probability is equal to the product of the probability of both events.</p><p><span class="math display">$$
P(A \cap B) = P(A) \times P(B)
$$</span></p><h3 id="assignment-1">Assignment 1</h3><p>A fair die is rolled. Let event A be «the face showing is even». Let event B «the face showing is odd». Are the events A and B independent?</p><h3 id="solution">Solution</h3><p>The probability that both events of the die A and B happens jointly is zero, for when an odd face is showing, no other face can show. So:</p><p><span class="math display">$$
P(A \cap B) = 0
$$</span></p><p>The probability of the event A is one half, for there are 3 even faces in a six-sided die. The same logic applies to B. Then:</p><p><span class="math display">$$
\begin{align}
P(A) &amp;= 1/2 \\\\
P(B) &amp;= 1/2 \\\\
P(A) \times P(B) &amp;= (1/2)*(1/2) = 1/4
\end{align}
$$</span></p><p>Because the joint probability is different to the product of the probability of the events, then the events are <strong>not</strong> independent.</p><p><span class="math display">$$
P(A \cap B) \ne P(A) \times P(B)
$$</span></p><p>A and B are called <strong>mutually exclusive events</strong>, but they are not independent. As a matter of fact, they are completely dependent, for if A occurs, B can’t, and <em>vice versa</em>.</p><h3 id="marginal-probability">Marginal probability</h3><p>The <strong>marginal probability</strong> of A is the probability of A in the joint event setting. It’s the probability of A occurring with B plus the probability of A whenever B is not met, i.e. <span class="math inline">\(\tilde{B}\)</span>.</p><p><span class="math display">$$
P(A) = P(A \cap B) + P(A \cap \tilde{B})
$$</span></p><h3 id="conditional-probability">Conditional probability</h3><p>The <strong>conditional</strong> probability is the probability of B conditioned to A, which is the joint probability of A and B over the marginal probability of A. In other words, the probability of A conditioned to the occurrence of A.</p><p><span class="math display">$$
P(B \mid A) = \frac{P(A \cap B)}{P(A)}
$$</span></p><p>For independent events it follows that the conditional probability of B given A is just the probability of B. The condition is then playing no role, of course, because both events are independent.</p><p><span class="math display">$$
P(B \mid A) = \frac{P(A \cap B)}{P(A)} = \frac{P(A) \times P(B)}{P(A)} = P(B)
$$</span></p><p>The <strong>multiplication rule</strong> is then defined as follows.</p><p><span class="math display">$$
P(A \cap B) = P(A \mid B) \times P(B) = P(B \mid A) \times P(A)
$$</span></p><h2 id="bayes-theorem">Bayes’ theorem</h2><p>Again, A is observed, and B is not. Then starting from the same definition for conditional probability as before.</p><p><span class="math display">$$
P(B \mid A) = \frac{P(A \cap B)}{P(A)}
$$</span></p><p>We can, then, make some substitutions, thus obtaining the Bayes’ theorem.</p><p><span class="math display">$$
P(B \mid A) = \frac{P(A \mid B) \times P(B)}{P(A \mid B) \times P(B) + P(A \mid \tilde{B}) \times P(\tilde{B})}
$$</span></p><h3 id="assignment-2">Assignment 2</h3><p>Suppose there is a mammographic screening procedure for breast cancer that has sensitivity = 0.9, and specificity 0.95. Suppose the underlying ratio of breast cancer in the female population is 0.001. Let B be the event «the woman has breast cancer», and let A be the event «the screening procedure gives a positive result».</p><p>What is the probability that a woman has the disease given a positive screening.</p><h3 id="solution-1">Solution</h3><p>First, we define the <em>a priori</em> probabilities, that is, the probabilities of having or not the disease prior the test. The sensitivity corresponds to <span class="math inline">\(P(A \mid B)\)</span>, and the specificity to <span class="math inline">\(1 - P(A \mid \tilde{B})\)</span>.</p><p><span class="math display">$$
P(B \mid A) = \frac{0.9 * 0.001}{0.9 * 0.001 + (1 - 0.95) * 0.999} \cong 0.0177
$$</span></p><p>Or in other words, the woman has close to a 1.77% probability of having the disease given a positive test.</p><h3 id="extension-of-the-theorem">Extension of the theorem</h3><p>The probability that we have arrived to works for any A and one single B. In the case for disjointed <span class="math inline">\(B_1, B_2, ..., B_n\)</span>, then.</p><p><span class="math display">$$
P(B_i \mid A) = \frac{P(A \mid B_i) \times P(B_i)}{\sum_{j=1}^{n} P(A \mid B_j) \times P(B_j)}
$$</span></p><p>The numerator comprehends the <strong>verisimilitude</strong>, i.e. <span class="math inline">\(P(A \mid B_i)\)</span>, times the prior probability.</p><h3 id="bayesian-universe">Bayesian universe</h3><p>A more systematic approach is presented. The universe is decomposed into mutually exclusive events and assigned prior probabilities. We call this events the unobserved dimension. Then, we perform an experiment A, which corresponds to the observed dimension, and compute the marginal probability for all <span class="math inline">\(B_n\)</span> events with A.</p><table class="ui table"><thead><tr><th>Prior probabilities</th><th>Updated probabilities</th></tr></thead><tbody><tr><td><span class="math inline">\(B_1\)</span></td><td><span class="math inline">\(B_1 \cap A\)</span></td></tr><tr><td><span class="math inline">\(B_2\)</span></td><td><span class="math inline">\(B_2 \cap A\)</span></td></tr><tr><td>…</td><td>…</td></tr><tr><td><span class="math inline">\(B_n\)</span></td><td><span class="math inline">\(B_n \cap A\)</span></td></tr></tbody></table><p>The resulting equation gives:</p><p><span class="math display">$$
P(B_i \mid A) \propto P(A \mid B_i) \times P(B_i)
$$</span></p><h3 id="binomial-distribution">Binomial distribution</h3><p>The <strong>binomial distribution</strong> is the discrete probability distribution of the number of successes in a sequence of <span class="math inline">\(n\)</span> independent experiments, each asking a yes-no question, and each with its own Boolean-valued outcome: success (with probability <span class="math inline">\(p\)</span>) or failure (with probability <span class="math inline">\(1 - p\)</span>).</p><p>We first introduce the choosing of <span class="math inline">\(n\)</span> elements of <span class="math inline">\(x\)</span>, i.e. <span class="math inline">\(n\)</span> choose <span class="math inline">\(x\)</span>, given by the formula:</p><p><span class="math display">$$
{n \choose x} = \frac{n!}{(n-x)! \ x!}
$$</span></p><p>The binomial distribution introduces two parameters, here <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>, where <span class="math inline">\(n\)</span> is the number of trials and <span class="math inline">\(p\)</span> the success probability. We then compute the probability of <span class="math inline">\(X\)</span> being a particular value (denoted as a lowercase <span class="math inline">\(x\)</span>), as follows.</p><p><span class="math display">$$
\begin{align}
X &amp;\sim \text{Bin}(n, p) \\\\
P(X = x) &amp;= {n \choose x} \, p^x \, (1-p)^{n-x}
\end{align}
$$</span></p><p>The binomial distribution is the basis of the binomial test of statistical significance.</p><h3 id="assignment-3">Assignment 3</h3><p>The proportion of patients infected with a particular bacteria after a given surgical procedure is unknown. Let assume five patients have been exposed to the surgical procedure. What is the prior distribution of the number of infected patients?</p><p>The biological material of one out of five operated patients is examined by an accurate diagnostic test, and the patient is infected. What is now the distribution of the number of infected patients?</p><h3 id="solution-2">Solution</h3><p>First we distribute the universe into mutually exclusive events and assign probabilities. In this case, there are six mutually exclusive events, that is 0 to 5 infected patients. We assume the same <strong>prior</strong> probability for each event, in this case, 1/6.</p><p>We compute the <strong>verisimilitudes</strong> using, for the case of <span class="math inline">\(x=1\)</span>:</p><p><span class="math display">$$
\begin{align}
X &amp;\sim \text{Bin}(n=1, p=1/5) \\\\
P(X=1) &amp;= {1 \choose 1} \ \frac{\ \ 1^{1}}{5} \ \left( 1- \frac{1}{5}\right) ^{1-1} \\\\
&amp;= 1/5
\end{align}
$$</span></p><p>And the product of both the prior and the verosimilitude gives us the <strong>product</strong>. We compute the sum of the products, <span class="math inline">\(\sum = 1/2\)</span>. Finally, we have to divide the product by it sum, i.e. the normalized product, or better, the <strong>posterior</strong> probability.</p><table class="ui table"><thead><tr><th>B</th><th>prior</th><th>verisimilitude</th><th>product</th><th>posterior</th></tr></thead><tbody><tr><td>x=0</td><td>1/6</td><td>0</td><td>0</td><td>0</td></tr><tr><td>x=1</td><td>1/6</td><td>1/5</td><td>1/30</td><td>1/15</td></tr><tr><td>x=2</td><td>1/6</td><td>2/5</td><td>2/30</td><td>2/15</td></tr><tr><td>x=3</td><td>1/6</td><td>3/5</td><td>3/30</td><td>3/15</td></tr><tr><td>x=4</td><td>1/6</td><td>4/5</td><td>4/30</td><td>4/15</td></tr><tr><td>x=5</td><td>1/6</td><td>5/5</td><td>5/30</td><td>5/15</td></tr></tbody></table></div><div class="metadata"><div class="date" title="Zettel date"><time datetime="2021-04-07T16:21">2021-04-07</time></div></div></article><nav class="ui attached segment deemphasized backlinksPane" id="neuron-backlinks-pane"><h3 class="ui header"><span title="Backlinks from folgezettel parents">Uplinks</span></h3><ul class="backlinks"><li><span class="zettel-link-container folge"><span class="zettel-link" title="2021-04-06T18:54"><a href="9f8d74d6.html">Methods for statistical analysis 1 (CAMAEI)</a><span data-nosnippet="" style="user-select: none; color: gray" title="Folgezettel">#</span></span></span><ul class="context-list" style="zoom: 85%;"><li class="item"><div class="pandoc"><span class="zettel-link-container folge"><span class="zettel-link" title="2021-04-07T16:21"><a href="c0fe92b6.html">Bayes&#39; theorem</a><span data-nosnippet="" style="user-select: none; color: gray" title="Folgezettel">#</span></span></span> — 07/04/2021</div></li></ul></li></ul></nav><nav class="ui attached segment deemphasized bottomPane" id="neuron-tags-pane"><div><span class="ui basic label zettel-tag" title="Tag">CAMAEI/lecture/01</span><span class="ui basic label zettel-tag" title="Tag">probability/Bayes-theorem</span><span class="ui basic label zettel-tag" title="Tag">probability/binomial-distribution</span><span class="ui basic label zettel-tag" title="Tag">prof/Justo-Lorenzo-Bermejo</span></div></nav><nav class="ui bottom attached icon compact inverted menu blue" id="neuron-nav-bar"><!--replace-start-9--><a class="item" href="." title="Home"><i class="home icon"></i></a><!--replace-end-9--><a class="right item" href="impulse.html" title="Open Impulse"><i class="wave square icon"></i></a></nav></div></div><!--replace-end-6--><!--replace-end-3--><!--replace-end-2--><div class="ui center aligned container footer-version"><div class="ui tiny image"><a href="https://neuron.zettel.page"><img alt="logo" src="https://raw.githubusercontent.com/srid/neuron/master/assets/neuron.svg" title="Generated by Neuron 1.9.25.1" /></a></div></div></div></body></html>